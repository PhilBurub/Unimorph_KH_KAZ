{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1c13377",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6aa541a",
   "metadata": {},
   "source": [
    "### 1. Parsing page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "1163ad4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_html(link):\n",
    "    page = requests.get(url=link)\n",
    "    page.encoding = 'utf=8'\n",
    "    parsed = BeautifulSoup(page.text)\n",
    "    triplets = []\n",
    "    for text in parsed.find_all('a', {'target': '_blank'}): # finding all texts\n",
    "        text_link = 'http://www.babel.gwi.uni-muenchen.de/' + text.attrs['href'].replace('view_corpus_file_new', 'view_glossed_corpus')\n",
    "        # formulating text link\n",
    "        text_page = requests.get(url=text_link)\n",
    "        text_page.encoding = 'utf=8'\n",
    "        triplets.extend(parse_page(text_page))\n",
    "    return triplets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f047be2b",
   "metadata": {},
   "source": [
    "### 2. Parsing a single glossed text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "6415fa94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_page(html):\n",
    "    triplets = []\n",
    "    parsed = BeautifulSoup(html.text)\n",
    "    for table in parsed.find_all('table', {'class': 'table_arr2table_new_glossed_text'}): # finding gloss tables\n",
    "        for word in table.find_all('table'): # finding word columns\n",
    "            word_form = word.find_all('td')[0].text\n",
    "            stem = word.find_all('td')[2].text.split('-')[0]\n",
    "            tags = [word.find_all('td')[4].text.split('-')[0]]\n",
    "            tags.extend(word.find_all('td')[3].text.split('-')[1:])\n",
    "            triplets.append({'lemma': stem, 'word_form': word_form, 'tags': ';'.join(tags)})\n",
    "    return triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "4e08ce1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "triplets = get_html('http://www.babel.gwi.uni-muenchen.de/index.php?abfrage=KK_corpus&subnavi=corpus_pub')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "b4435443",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83090"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(triplets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "135e9401",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('website_parsed.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(triplets, f, indent='\\t', ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8bd342",
   "metadata": {},
   "source": [
    "### 3. Converting data to our format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cca489a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('website_parsed.json', 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fd34047f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv(data):\n",
    "    \n",
    "    def yield_data(data):\n",
    "        for key in data:\n",
    "            yield(key['lemma'], key['word_form'], key['tags'])\n",
    "    \n",
    "    def web2kaz(text):\n",
    "        text = text.replace('aː', 'ă').replace('ɵː', 'ɵ').replace('ɔː', 'o').replace('sʲ', 'ś').replace('eː', 'ɛ')\n",
    "        text = text.replace('nʲ', 'ń').replace('o', 'u').replace('u', 'ʉ').replace('ɬ', 'λ').replace('β', 'w')\n",
    "        text = text.replace('x', 'χ').replace('ʃ', 'š').replace('ʲ', 'ˊ')\n",
    "        return text\n",
    "        \n",
    "    my_list =[]\n",
    "    for lemma, word_form, tags in yield_data(data):\n",
    "        data_dict = {}\n",
    "        data_dict['lemma'] = web2kaz(lemma)\n",
    "        data_dict['word_form'] = web2kaz(word_form)\n",
    "        data_dict['tags'] = tags\n",
    "        my_list.append(data_dict)\n",
    "    \n",
    "    return my_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "89003ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "converted_data = conv(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "83623ddd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83090"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(converted_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c0cb4672",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_format = set()\n",
    "for triplet in converted_data:\n",
    "    write_format.add(f\"{triplet['lemma']}\\t{triplet['word_form']}\\t{triplet['tags']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7a63a204",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('website_unidraft.tsv', 'w', encoding='utf-8') as f:\n",
    "    f.write(''.join(sorted(write_format)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
